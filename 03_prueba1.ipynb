{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianCarvajal/ProyectoIA/blob/main/03_prueba1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "NhbfrIp4KlCQ",
        "outputId": "c61e357e-bd01-43dc-efd1-4864d55b75ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<meta name=\"google-signin-client_id\"\n",
              "      content=\"461673936472-kdjosv61up3ac1ajeuq6qqu72upilmls.apps.googleusercontent.com\"/>\n",
              "<script src=\"https://apis.google.com/js/client:platform.js?onload=google_button_start\"></script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replicating local resources\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h3>See <a href='https://m5knaekxo6.execute-api.us-west-2.amazonaws.com/dev-v0001/rlxmooc/web/login' target='_blank'>my courses and progress</a></h2>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/ai4eng.v1/main/content/init.py\n",
        "import init; init.init(force_download=False); init.get_weblink()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4H-zDqDWB3r",
        "outputId": "49a1c6e0-af55-4e0a-d36e-182817b21784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/235.8 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m235.5/235.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRaVMI-v0re",
        "outputId": "128b7468-4509-4c7e-a8be-c2a3a8a796d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GZqdgdEK7rB"
      },
      "source": [
        "## download data directly from Kaggle\n",
        "\n",
        "- create a file `kaggle.json` with your authentication token (in kaggle $\\to$ click user icon on top-right $\\to$ settings $\\to$ API create new token)\n",
        "- upload it to this notebook workspace\n",
        "- run the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Px7YBcK3OY",
        "outputId": "f65bbc83-c7b1-4c53-df3f-a1990b41e158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 432MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWFKQdWNZ83"
      },
      "source": [
        "## unzip and inspect data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0D1i3q9NaaP"
      },
      "outputs": [],
      "source": [
        "!unzip udea*.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7QgZbBNdNy",
        "outputId": "f34c64e4-d0b0-4cfb-fea1-e212e78c5bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   296787    296787   4716673 submission_example.csv\n",
            "   296787   4565553  59185250 test.csv\n",
            "   692501  10666231 143732449 train.csv\n",
            "  1286075  15528571 207634372 total\n"
          ]
        }
      ],
      "source": [
        "!wc *.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmS6Di4nyVH"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFNqTXp0NgJI",
        "outputId": "1e3df3bc-6993-4d1d-8055-df087d62c788"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(692500, 21)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('train.csv', encoding = 'utf-8')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nbCybnoucwI"
      },
      "source": [
        "## Funciones reutilizables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BgR247-ug5M"
      },
      "outputs": [],
      "source": [
        "from unidecode import unidecode\n",
        "\n",
        "def clean_text(colum_name):\n",
        "  df[colum_name] = (\n",
        "      df[colum_name]\n",
        "      .astype(str)                            # Asegura que todo sea texto\n",
        "      .str.lower()                            # Convierte a minúsculas\n",
        "      .str.strip()                            # Quita espacios al principio/final\n",
        "      .apply(unidecode)                       # Elimina tildes\n",
        "      .str.replace(r'\\s+', ' ', regex=True)   # Sustituye múltiples espacios por uno solo\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czfdv3UQzApn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rapidfuzz import fuzz, process\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "# --- 1. Función de Pre-procesamiento Robusto (Sin cambios, ya está en la función de limpieza) ---\n",
        "def preprocesar_texto(texto):\n",
        "    texto = str(texto).lower()\n",
        "    texto = unidecode(texto)\n",
        "    texto = re.sub(r'[^a-z0-9\\s]', '', texto) # Esto maneja el '?' y otros especiales\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto\n",
        "\n",
        "# --- 2. Función de Limpieza de Columna con Fuzzy Matching (MEJORADA CON DEBUG) ---\n",
        "def limpiar_columna_fuzzy_debug(df, columna_a_limpiar, umbral=85):\n",
        "    df_temp = df.copy()\n",
        "\n",
        "    # Aplicar el pre-procesamiento a una nueva columna temporal\n",
        "    columna_preprocesada = f\"{columna_a_limpiar}_preprocesada\"\n",
        "    df_temp[columna_preprocesada] = df_temp[columna_a_limpiar].apply(preprocesar_texto)\n",
        "\n",
        "    # Obtener los programas únicos de la columna pre-procesada\n",
        "    programas_unicos_preproc = df_temp[columna_preprocesada].unique().tolist()\n",
        "\n",
        "    mapeo_programas_preproc_a_canonico = {}\n",
        "    programas_preproc_procesados = set()\n",
        "\n",
        "    # Iterar sobre cada programa único pre-procesado\n",
        "    for i, programa_actual_preproc in enumerate(programas_unicos_preproc):\n",
        "        if programa_actual_preproc in programas_preproc_procesados:\n",
        "            continue\n",
        "\n",
        "        nombre_canonico_preproc = programa_actual_preproc\n",
        "        mapeo_programas_preproc_a_canonico[programa_actual_preproc] = nombre_canonico_preproc\n",
        "        programas_preproc_procesados.add(programa_actual_preproc)\n",
        "        print(f\"\\n[{i+1}/{len(programas_unicos_preproc)}] Estableciendo canónico: '{nombre_canonico_preproc}'\")\n",
        "\n",
        "        # Busca coincidencias entre este canónico y los programas que aún no se han mapeado\n",
        "        opciones_a_comparar = [p for p in programas_unicos_preproc if p not in programas_preproc_procesados]\n",
        "\n",
        "        if not opciones_a_comparar:\n",
        "            print(f\"  No hay más opciones para comparar con '{nombre_canonico_preproc}'.\")\n",
        "            continue\n",
        "\n",
        "        coincidencias = process.extract(\n",
        "            query=programa_actual_preproc,\n",
        "            choices=opciones_a_comparar,\n",
        "            scorer=fuzz.token_set_ratio,\n",
        "            limit=None\n",
        "        )\n",
        "\n",
        "        found_match_in_group = False\n",
        "        for posible_variacion_preproc, puntuacion, _ in coincidencias:\n",
        "            if puntuacion >= umbral:\n",
        "                if posible_variacion_preproc not in programas_preproc_procesados:\n",
        "                    mapeo_programas_preproc_a_canonico[posible_variacion_preproc] = nombre_canonico_preproc\n",
        "                    programas_preproc_procesados.add(posible_variacion_preproc)\n",
        "                    print(f\"  -> Mapeando '{posible_variacion_preproc}' (score: {puntuacion}) a '{nombre_canonico_preproc}'\")\n",
        "                    found_match_in_group = True\n",
        "            # DEBUG: Mostrar coincidencias cercanas pero que no cumplen el umbral\n",
        "            elif puntuacion > umbral - 15: # Mostrar si la puntuación es ~15 puntos por debajo del umbral\n",
        "                 print(f\"  -> IGNORANDO '{posible_variacion_preproc}' (score: {puntuacion}) para '{nombre_canonico_preproc}' - Puntuación muy baja.\")\n",
        "\n",
        "        if not found_match_in_group and len(opciones_a_comparar) > 0:\n",
        "            print(f\"  No se encontraron coincidencias por encima del umbral={umbral} para '{nombre_canonico_preproc}' en las {len(opciones_a_comparar)} opciones restantes.\")\n",
        "\n",
        "\n",
        "    # --- Paso para obtener la forma ORIGINAL del nombre canónico ---\n",
        "    # Crear un mapeo inverso de la forma preprocesada canónica a una de sus formas originales\n",
        "    canonical_preproc_a_original_map = {}\n",
        "    for original_val, preprocessed_val in df_temp[[columna_a_limpiar, columna_preprocesada]].drop_duplicates().values:\n",
        "        if preprocessed_val in mapeo_programas_preproc_a_canonico:\n",
        "            cleaned_preprocessed_val = mapeo_programas_preproc_a_canonico[preprocessed_val]\n",
        "            if cleaned_preprocessed_val not in canonical_preproc_a_original_map:\n",
        "                canonical_preproc_a_original_map[cleaned_preprocessed_val] = original_val\n",
        "        else:\n",
        "            # En casos muy raros donde un preprocesado no fue mapeado (debería ser handled por el 'else' del bucle)\n",
        "            if preprocessed_val not in canonical_preproc_a_original_map:\n",
        "                canonical_preproc_a_original_map[preprocessed_val] = original_val\n",
        "\n",
        "    # Aplicar este mapeo para obtener la columna final limpia con nombres originales\n",
        "    df_temp[f'{columna_a_limpiar}_limpio'] = df_temp[f'{columna_a_limpiar}_preprocesada'].map(mapeo_programas_preproc_a_canonico).map(canonical_preproc_a_original_map)\n",
        "\n",
        "    # Eliminar las columnas temporales preprocesadas\n",
        "    df_final = df_temp.drop(columns=[columna_preprocesada]) # Ya no necesitamos la preproc, ni la limpia_preproc\n",
        "\n",
        "    # Construir el diccionario de mapeo final (original -> original_limpio) para el retorno\n",
        "    final_mapeo_para_retornar = {}\n",
        "    for original_val in df[columna_a_limpiar].unique():\n",
        "        preprocessed_val = preprocesar_texto(original_val)\n",
        "        if preprocessed_val in mapeo_programas_preproc_a_canonico:\n",
        "            cleaned_preprocessed_val = mapeo_programas_preproc_a_canonico[preprocessed_val]\n",
        "            final_mapeo_para_retornar[original_val] = canonical_preproc_a_original_map.get(cleaned_preprocessed_val, original_val)\n",
        "        else:\n",
        "            # Fallback en caso de que un valor original no se haya mapeado (raro)\n",
        "            final_mapeo_para_retornar[original_val] = original_val\n",
        "\n",
        "    num_unicos_final = len(df_final[f'{columna_a_limpiar}_limpio'].unique())\n",
        "    # print(\"\\n----------------------------------------------------------------------\")\n",
        "    # print(f\"Número de programas únicos DESPUÉS de limpieza: {num_unicos_final}\")\n",
        "    # if num_unicos_final == len(programas_unicos_preproc):\n",
        "    #     print(\"ADVERTENCIA: No se realizó ninguna agrupación. Considera bajar el umbral o revisar tus datos.\")\n",
        "    # print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "    return df_final, final_mapeo_para_retornar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DhFydTSn68d"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXuj2gshoFY9"
      },
      "source": [
        "### Codificación de variables categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpYfnRQCob7i"
      },
      "source": [
        "#### Rendimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SXRTwYkdup1"
      },
      "outputs": [],
      "source": [
        "def clean_performance(df):\n",
        "  maped_performance_values = {'bajo': 1, 'medio-bajo':2, 'medio-alto':3, 'alto':4}\n",
        "  df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(maped_performance_values)\n",
        "  return df['RENDIMIENTO_GLOBAL']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV609Yx1oejG"
      },
      "source": [
        "#### Familia con internet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZb-0LdewijL"
      },
      "outputs": [],
      "source": [
        "def clean_internet(df):\n",
        "  maped_internet_values = {'Si': 1, 'No':0}\n",
        "  df['FAMI_TIENEINTERNET'] = df['FAMI_TIENEINTERNET'].map(maped_internet_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nnf51a4pM1H"
      },
      "source": [
        "#### Familia con internet (Columna repetida con \"si\" y \"no\" cómo respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eg0HaQOEI7D"
      },
      "outputs": [],
      "source": [
        "def clean_internet_1(df):\n",
        "  del(df['FAMI_TIENEINTERNET.1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTaXTKr8oifM"
      },
      "source": [
        "#### Valor matrícula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09wIGgcy1ojm"
      },
      "outputs": [],
      "source": [
        "def clean_matr(df):\n",
        "  maped_tuition_values = {'No pagó matrícula': 0,\n",
        "                          'Menos de 500 mil':1,\n",
        "                          'Entre 500 mil y menos de 1 millón':2,\n",
        "                          'Entre 1 millón y menos de 2.5 millones':3,\n",
        "                          'Entre 2.5 millones y menos de 4 millones':4,\n",
        "                          'Entre 4 millones y menos de 5.5 millones':5,\n",
        "                          'Entre 5.5 millones y menos de 7 millones':6,\n",
        "                          'Más de 7 millones':7}\n",
        "  df['ESTU_VALORMATRICULAUNIVERSIDAD'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map(maped_tuition_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDe0amw9omjd"
      },
      "source": [
        "#### Horas de trabajo semanales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plbfP0Mk4Cwz"
      },
      "outputs": [],
      "source": [
        "def clean_work_hours(df):\n",
        "  maped_working_values = {'0': 0,\n",
        "                          'Menos de 10 horas':1,\n",
        "                          'Entre 11 y 20 horas':2,\n",
        "                          'Entre 21 y 30 horas':3,\n",
        "                          'Más de 30 horas':4}\n",
        "  df['ESTU_HORASSEMANATRABAJA'] = df['ESTU_HORASSEMANATRABAJA'].map(maped_working_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXXz_IjrorVd"
      },
      "source": [
        "#### Estrato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsELECsl4ZiD"
      },
      "outputs": [],
      "source": [
        "def clean_stratum(df):\n",
        "  maped_estrato_values = {'0': 0,\n",
        "                          'Estrato 1':1,\n",
        "                          'Estrato 2':2,\n",
        "                          'Estrato 3':3,\n",
        "                          'Estrato 4':4,\n",
        "                          'Estrato 5':5,\n",
        "                          'Estrato 6':6}\n",
        "  df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].map(maped_estrato_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGEfh3hVovcq"
      },
      "source": [
        "#### Educación padre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuv3IB7JAnYX"
      },
      "outputs": [],
      "source": [
        "def clean_p_education(df):\n",
        "  maped_education_values = {'Ninguno': 0,\n",
        "                          'Primaria incompleta':1,\n",
        "                          'Primaria completa':2,\n",
        "                          'Secundaria (Bachillerato) incompleta':3,\n",
        "                          'Secundaria (Bachillerato) completa':4,\n",
        "                          'Técnica o tecnológica incompleta':5,\n",
        "                          'Técnica o tecnológica completa':6,\n",
        "                          'Educación profesional incompleta':7,\n",
        "                          'Educación profesional completa':8,\n",
        "                          'Postgrado':9}\n",
        "  df['FAMI_EDUCACIONPADRE'] = df['FAMI_EDUCACIONPADRE'].map(maped_education_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRdyNFFrpXnW"
      },
      "source": [
        "#### Educación madre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdU2jAziEghL"
      },
      "outputs": [],
      "source": [
        "def clean_m_education(df):\n",
        "  maped_education_values = {'Ninguno': 0,\n",
        "                          'Primaria incompleta':1,\n",
        "                          'Primaria completa':2,\n",
        "                          'Secundaria (Bachillerato) incompleta':3,\n",
        "                          'Secundaria (Bachillerato) completa':4,\n",
        "                          'Técnica o tecnológica incompleta':5,\n",
        "                          'Técnica o tecnológica completa':6,\n",
        "                          'Educación profesional incompleta':7,\n",
        "                          'Educación profesional completa':8,\n",
        "                          'Postgrado':9}\n",
        "  df['FAMI_EDUCACIONMADRE'] = df['FAMI_EDUCACIONMADRE'].map(maped_education_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJomTbpDoxso"
      },
      "source": [
        "#### Tiene lavadora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb1DDgiYBVM5"
      },
      "outputs": [],
      "source": [
        "def clean_washing_machine(df):\n",
        "  maped_washing_values = {'No': 0,\n",
        "                          'Si': 1}\n",
        "  df['FAMI_TIENELAVADORA'] = df['FAMI_TIENELAVADORA'].map(maped_washing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ptDULoo0LC"
      },
      "source": [
        "#### Tiene automovil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnhw45niB6aW"
      },
      "outputs": [],
      "source": [
        "def clean_car(df):\n",
        "  maped_car_values = {'No': 0,\n",
        "                      'Si': 1}\n",
        "  df['FAMI_TIENEAUTOMOVIL'] = df['FAMI_TIENEAUTOMOVIL'].map(maped_car_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZDAs6R8o3Ko"
      },
      "source": [
        "#### Privado de la libertad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GztcKgHxCZCY"
      },
      "outputs": [],
      "source": [
        "def clean_priv_lib(df):\n",
        "  maped_estu_priv_values = {'N': 0,\n",
        "                      'S': 1}\n",
        "  df['ESTU_PRIVADO_LIBERTAD'] = df['ESTU_PRIVADO_LIBERTAD'].map(maped_estu_priv_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnq9_y2NpA0I"
      },
      "source": [
        "#### Se paga su matrícula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQY1nmjLDfb1"
      },
      "outputs": [],
      "source": [
        "def clean_own_pay(df):\n",
        "  maped_ownpay_values = {'No': 0,\n",
        "                      'Si': 1}\n",
        "  df['ESTU_PAGOMATRICULAPROPIO'] = df['ESTU_PAGOMATRICULAPROPIO'].map(maped_ownpay_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC-vs8LtpFn9"
      },
      "source": [
        "#### Tiene computador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4wGDRBlDuHr"
      },
      "outputs": [],
      "source": [
        "def clean_own_pc(df):\n",
        "  maped_ownpc_values = {'No': 0,\n",
        "                      'Si': 1}\n",
        "  df['FAMI_TIENECOMPUTADOR'] = df['FAMI_TIENECOMPUTADOR'].map(maped_ownpc_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok5eLnsr-ptc"
      },
      "source": [
        "### Codificación One-hot encoding para variables categóricas no ordinales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCG8ItEB_Kkg"
      },
      "outputs": [],
      "source": [
        "def clean_dpto(df):\n",
        "  df['ESTU_PRGM_DEPARTAMENTO'] = df['ESTU_PRGM_DEPARTAMENTO'].str.strip().str.upper()\n",
        "\n",
        "  df_aux = pd.get_dummies(df,\n",
        "                              columns=['ESTU_PRGM_DEPARTAMENTO'],\n",
        "                              prefix='DEPTO',\n",
        "                              prefix_sep='_',\n",
        "                              dtype='uint8')\n",
        "  return df_aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL9SxuEXdHHj"
      },
      "outputs": [],
      "source": [
        "def clean_periodo(df):\n",
        "  df_aux = pd.get_dummies(df,\n",
        "                              columns=['PERIODO'],\n",
        "                              prefix='PERIODO',\n",
        "                              prefix_sep='_',\n",
        "                              dtype='uint8')\n",
        "  return df_aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9TrRo-5ddCc"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "def clean_program(df):\n",
        "  # Paso 1: Crear una función de limpieza para normalizar los nombres de los programas.\n",
        "  def limpiar_texto(texto):\n",
        "      if not isinstance(texto, str):\n",
        "          return texto\n",
        "\n",
        "      texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
        "      texto = texto.lower().strip().replace('-', ' ').replace('.', '').replace(',', '')\n",
        "      return ' '.join(texto.split())\n",
        "\n",
        "  # Paso 2: Aplicar la limpieza para crear una columna de trabajo temporal.\n",
        "  df['ESTU_PRGM_ACADEMICO_LIMPIO'] = df['ESTU_PRGM_ACADEMICO'].apply(limpiar_texto)\n",
        "  del(df['ESTU_PRGM_ACADEMICO'])\n",
        "  print(\"aaaaaaaaa\")\n",
        "  # Paso 3: Agrupar por frecuencia (mantenemos los 30 programas mas frecuentes).\n",
        "  N = 30\n",
        "  top_n_programas = df['ESTU_PRGM_ACADEMICO_LIMPIO'].value_counts().nlargest(N).index\n",
        "\n",
        "  # Creamos otra columna temporal con los programas agrupados.\n",
        "  df['PRGM_AGRUPADO_TEMP'] = df['ESTU_PRGM_ACADEMICO_LIMPIO'].where(df['ESTU_PRGM_ACADEMICO_LIMPIO'].isin(top_n_programas), 'OTRO')\n",
        "\n",
        "  # Paso 4: Aplicar One-Hot Encoding sobre la columna agrupada.\n",
        "  df = pd.get_dummies(df, columns=['PRGM_AGRUPADO_TEMP'], prefix='PRGM', dtype=int)\n",
        "\n",
        "  # Paso 5: Limpieza final. Eliminamos las columnas temporales que creamos.\n",
        "  # Las columnas originales no se tocan.\n",
        "  del(df['ESTU_PRGM_ACADEMICO_LIMPIO'])\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5cdjCDGeJgP"
      },
      "source": [
        "## Tratamiento de datos nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgbEvmq5eLr3"
      },
      "outputs": [],
      "source": [
        "def clean_nulls(df):\n",
        "  columnas_numericas = [\n",
        "      'ESTU_VALORMATRICULAUNIVERSIDAD',\n",
        "      'ESTU_HORASSEMANATRABAJA'\n",
        "  ]\n",
        "\n",
        "  columnas_categoricas = [\n",
        "      'FAMI_ESTRATOVIVIENDA', 'FAMI_TIENEINTERNET', 'FAMI_EDUCACIONPADRE',\n",
        "      'FAMI_TIENELAVADORA', 'FAMI_TIENEAUTOMOVIL', 'ESTU_PAGOMATRICULAPROPIO',\n",
        "      'FAMI_TIENECOMPUTADOR', 'FAMI_EDUCACIONMADRE'\n",
        "  ]\n",
        "\n",
        "  # 1. Reemplazamos los valores nulos con la mediana\n",
        "  for col in columnas_numericas:\n",
        "      mediana = df[col].median()\n",
        "      df[col] = df[col].fillna(mediana)\n",
        "\n",
        "  # 2. Reemplazamos los valores nulos con la MODA\n",
        "  for col in columnas_categoricas:\n",
        "      moda = df[col].mode()[0]\n",
        "      df[col] = df[col].fillna(moda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPnst9kPpbCB"
      },
      "source": [
        "## Get Data ready for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBThlDey2nG5"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "  # clean_performance(df)\n",
        "  clean_internet(df)\n",
        "  clean_internet_1(df)\n",
        "  clean_matr(df)\n",
        "  clean_work_hours(df)\n",
        "  clean_stratum(df)\n",
        "  clean_p_education(df)\n",
        "  clean_m_education(df)\n",
        "  clean_washing_machine(df)\n",
        "  clean_car(df)\n",
        "  clean_priv_lib(df)\n",
        "  clean_own_pay(df)\n",
        "  clean_own_pc(df)\n",
        "  df = clean_dpto(df)\n",
        "  df = clean_periodo(df)\n",
        "  df = clean_program(df)\n",
        "  clean_nulls(df)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lcWzJ_N1Wbx",
        "outputId": "6fcb7aa0-080c-488d-c313-08a68cd8a809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((692500, 21), (296786, 20))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtr = pd.read_csv('train.csv', encoding = 'utf-8')\n",
        "dts = pd.read_csv('test.csv', encoding = 'utf-8')\n",
        "lentr = len(dtr)\n",
        "dtr.shape, dts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjqWqYyyhiXt",
        "outputId": "bc020e28-c410-4713-af18-e8352935e572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aaaaaaaaa\n",
            "(692500, 87) (692500,) (296786, 87)\n"
          ]
        }
      ],
      "source": [
        "source_cols = [i for i in dtr.columns if i != 'RENDIMIENTO_GLOBAL']\n",
        "all_data = pd.concat([dtr[source_cols], dts[source_cols]])\n",
        "all_data.index = range(len(all_data))\n",
        "all_data = clean_data(all_data)\n",
        "\n",
        "xtr, ytr = all_data.iloc[:lentr].values, clean_performance(dtr).values\n",
        "xts = all_data.iloc[lentr:].values\n",
        "\n",
        "print(xtr.shape, ytr.shape, xts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ3ryM6o6A9m",
        "outputId": "303fd05a-f1c3-4431-f378-91e697569f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4019278  0.40129964 0.4025343  0.40228881 0.40250542]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "rf = RandomForestClassifier()\n",
        "print (cross_val_score(rf, xtr, ytr))\n",
        "\n",
        "svc = SVC()\n",
        "print (cross_val_score(svc, xtr, ytr))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7GZqdgdEK7rB",
        "9MWFKQdWNZ83",
        "itmS6Di4nyVH",
        "tXuj2gshoFY9",
        "RpYfnRQCob7i",
        "NV609Yx1oejG",
        "_Nnf51a4pM1H",
        "vTaXTKr8oifM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}